{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Dog vs cat in Kaggle](https://www.kaggle.com/c/dogs-vs-cats)\n",
    "- [Original note book](https://github.com/fastai/courses/blob/master/deeplearning1/nbs/lesson1.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup\n",
    "Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run env_setup.py\n",
    "from importlib import reload\n",
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets.kaggle import dog_cat\n",
    "reload(dog_cat)\n",
    "\n",
    "data_dir = dog_cat.download_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = os.path.join(data_dir, 'sample')\n",
    "path = data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use pretrained VGG model\n",
    "\n",
    "- VGG19: large, slow, slightly accurate\n",
    "- VGG16: small, fast\n",
    "\n",
    "We use VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## As large as you can, but no larger than 64 is recommanded\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import vgg16\n",
    "reload(vgg16)\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\learn\\online_course\\notes\\fast_ai\\deeplearning1\\vgg16.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
      "D:\\learn\\online_course\\notes\\fast_ai\\deeplearning1\\vgg16.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
      "D:\\learn\\online_course\\notes\\fast_ai\\deeplearning1\\vgg16.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "  model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
      "D:\\learn\\online_course\\notes\\fast_ai\\deeplearning1\\vgg16.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "  model.add(Convolution2D(filters, 3, 3, activation='relu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/1\n",
      "359/359 [==============================] - 151s - loss: 0.4408 - acc: 0.8691 - val_loss: 0.2688 - val_acc: 0.9047\n"
     ]
    }
   ],
   "source": [
    "vgg = Vgg16()\n",
    "batches = vgg.get_batches(os.path.join(path, 'train'), batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(os.path.join(path, 'valid'), batch_size=batch_size)\n",
    "\n",
    "vgg.finetune(batches)\n",
    "vgg.fit(batches, val_batches, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs, labels = batches.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "print(imgs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
