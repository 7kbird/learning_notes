{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run env_setup.py\n",
    "import lessdeep as ld\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "Successfully downloaded nietzsche.txt 600901 bytes.\n"
     ]
    }
   ],
   "source": [
    "src_path = ld.utils.download_file(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 600893\n"
     ]
    }
   ],
   "source": [
    "with open(src_path) as f:\n",
    "    text = f.read()\n",
    "print('Length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print('Vocabulary size:', vocab_size)\n",
    "chars[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 85\n"
     ]
    }
   ],
   "source": [
    "# Add '\\0' for padding\n",
    "chars.insert(0, '\\0')\n",
    "vocab_size += 1\n",
    "print('Vocabulary size:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {c:i for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real input\n",
    "idx = [char2idx[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not ground\\nfor su'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([chars[i] for i in idx[:80]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 char model\n",
    "\n",
    "Create inputdata of length 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input(length):\n",
    "    return [np.array([idx[i + offset] for i in range(0, len(idx)-1-length, length)]) for offset in range(length+1)]\n",
    "all_data = generate_input(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_data[:-1]\n",
    "y = all_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(200297,), (200297,), (200297,)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a.shape for a in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_input(name, input_size, output_size, **kwargs):\n",
    "    inp = keras.layers.Input(shape=(1,), dtype=np.int32, name=name)\n",
    "    emb = keras.layers.Embedding(input_dim=input_size, output_dim=output_size, input_length=1, **kwargs)(inp)\n",
    "    \n",
    "    return inp, keras.layers.Flatten()(emb)\n",
    "embeddings = [embedding_input('c{0}'.format(i), vocab_size, feature_size) for i in range(3)]\n",
    "c_in, c_emb = list(zip(*embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dense = keras.layers.Dense(dense_size, activation='relu', name='input_dense')\n",
    "res_dense = keras.layers.Dense(dense_size, activation='tanh', name='res_dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "c0 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 42)        3570        c0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "c1 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 42)           0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 42)        3570        c1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "input_dense (Dense)             multiple             11008       flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 42)           0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c2 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "res_dense (Dense)               multiple             65792       input_dense[20][0]               \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 1, 42)        3570        c2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 256)          0           res_dense[13][0]                 \n",
      "                                                                 input_dense[21][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 42)           0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 256)          0           res_dense[14][0]                 \n",
      "                                                                 input_dense[22][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_dense (Dense)            (None, 85)           21845       add_14[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 109,355\n",
      "Trainable params: 109,355\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def merge_dense(a, b):\n",
    "    return keras.layers.add([res_dense(a), input_dense(b)])\n",
    "out1 = merge_dense(input_dense(c_emb[0]), c_emb[1])\n",
    "out2 = merge_dense(out1, c_emb[2])\n",
    "final_out = keras.layers.Dense(vocab_size, activation='softmax', name='output_dense')(out2)\n",
    "model = keras.models.Model(inputs=c_in, outputs=final_out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=lr), loss=keras.losses.sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "200297/200297 [==============================] - 6s 29us/step - loss: 2.0605\n",
      "Epoch 2/2\n",
      "200297/200297 [==============================] - 5s 26us/step - loss: 2.0360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b2f88f5160>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=256, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_next(seq, seq_len):\n",
    "    seq_idx = [char2idx[c] for c in seq[-seq_len:]]\n",
    "    prop = model.predict([np.array(c)[np.newaxis] for c in seq_idx])[0]\n",
    "    return chars[np.argmax(prop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next(' th', seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 8\n",
    "all_data = generate_input(seq_len)\n",
    "x = np.stack(all_data[:-1], axis=1)\n",
    "y = all_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 8, 42)             3570      \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 256)               76544     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 85)                21845     \n",
      "=================================================================\n",
      "Total params: 101,959\n",
      "Trainable params: 101,959\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=vocab_size, output_dim=feature_size, input_length=seq_len),\n",
    "    keras.layers.SimpleRNN(dense_size, recurrent_initializer='identity', activation='relu'),\n",
    "    keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=keras.losses.sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "75111/75111 [==============================] - 7s 97us/step - loss: 1.5816\n",
      "Epoch 2/4\n",
      "75111/75111 [==============================] - 7s 97us/step - loss: 1.5395\n",
      "Epoch 3/4\n",
      "75111/75111 [==============================] - 7s 97us/step - loss: 1.5030\n",
      "Epoch 4/4\n",
      "75111/75111 [==============================] - 7s 97us/step - loss: 1.4684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b2fe07d518>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(x), y, batch_size=64, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(seq, seq_len):\n",
    "    seq_idx = [char2idx[c] for c in seq[-seq_len:]]\n",
    "    prop = model.predict(np.array([seq_idx]))[0]\n",
    "    return chars[np.argmax(prop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('this is ti', seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "seq_len = 8\n",
    "x = [np.array([idx[i + offset] for i in range(0, len(idx)-1-seq_len, seq_len)]) for offset in range(seq_len)]\n",
    "y = [np.array([idx[i + offset] for i in range(1, len(idx)-1-seq_len, seq_len)]) for offset in range(seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([40,  1, 33,  2, 72, 67, 73,  2, 68, 57]),\n",
       " array([42,  1, 38, 44,  2,  9, 61, 73, 73,  1]),\n",
       " array([29, 43, 31, 71, 54,  9, 58, 61,  2, 59]),\n",
       " array([30, 45,  2, 74,  2, 76, 67, 58, 60, 68]),\n",
       " array([25, 40, 73, 73, 76, 61, 24, 71, 71, 71]),\n",
       " array([27, 40, 61, 61, 68, 54,  2, 58, 68,  2]),\n",
       " array([29, 39, 54,  2, 66, 73, 33,  2, 74, 72]),\n",
       " array([ 1, 43, 73, 62, 54,  2, 72, 67, 67, 74])]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[i][:10] for i in range(seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([42,  1, 38, 44,  2,  9, 61, 73, 73,  1]),\n",
       " array([29, 43, 31, 71, 54,  9, 58, 61,  2, 59]),\n",
       " array([30, 45,  2, 74,  2, 76, 67, 58, 60, 68]),\n",
       " array([25, 40, 73, 73, 76, 61, 24, 71, 71, 71]),\n",
       " array([27, 40, 61, 61, 68, 54,  2, 58, 68,  2]),\n",
       " array([29, 39, 54,  2, 66, 73, 33,  2, 74, 72]),\n",
       " array([ 1, 43, 73, 62, 54,  2, 72, 67, 67, 74]),\n",
       " array([ 1, 33,  2, 72, 67, 73,  2, 68, 57, 72])]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y[i][:10] for i in range(seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model\n",
    "embeddings = [embedding_input('c{0}'.format(i), vocab_size, feature_size) for i in range(seq_len)]\n",
    "c_in, c_emb = list(zip(*embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense layers\n",
    "dense_in = keras.layers.Dense(dense_size,activation='relu', name='seq_dense_in')\n",
    "dense_res = keras.layers.Dense(dense_size, activation='relu', name='seq_dense_res', kernel_initializer='identity')\n",
    "dense_out = keras.layers.Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "c0 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 1, 42)        3570        c0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 42)           0           embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zeros (InputLayer)              (None, 42)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "seq_dense_in (Dense)            (None, 42)           1806        zeros[0][0]                      \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "c1 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "seq_dense_res (Dense)           (None, 42)           1806        seq_dense_in[26][0]              \n",
      "                                                                 add_38[0][0]                     \n",
      "                                                                 add_39[0][0]                     \n",
      "                                                                 add_40[0][0]                     \n",
      "                                                                 add_41[0][0]                     \n",
      "                                                                 add_42[0][0]                     \n",
      "                                                                 add_43[0][0]                     \n",
      "                                                                 add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1, 42)        3570        c1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 42)           0           seq_dense_in[27][0]              \n",
      "                                                                 seq_dense_res[23][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 42)           0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c2 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 42)        3570        c2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 42)           0           seq_dense_in[28][0]              \n",
      "                                                                 seq_dense_res[24][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 42)           0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c3 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 1, 42)        3570        c3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 42)           0           seq_dense_in[29][0]              \n",
      "                                                                 seq_dense_res[25][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 42)           0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c4 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 1, 42)        3570        c4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 42)           0           seq_dense_in[30][0]              \n",
      "                                                                 seq_dense_res[26][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 42)           0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c5 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 1, 42)        3570        c5[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 42)           0           seq_dense_in[31][0]              \n",
      "                                                                 seq_dense_res[27][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 42)           0           embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c6 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 1, 42)        3570        c6[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 42)           0           seq_dense_in[32][0]              \n",
      "                                                                 seq_dense_res[28][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 42)           0           embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c7 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 1, 42)        3570        c7[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 42)           0           seq_dense_in[33][0]              \n",
      "                                                                 seq_dense_res[29][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 42)           0           embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 42)           0           seq_dense_in[34][0]              \n",
      "                                                                 seq_dense_res[30][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 85)           3655        add_38[0][0]                     \n",
      "                                                                 add_39[0][0]                     \n",
      "                                                                 add_40[0][0]                     \n",
      "                                                                 add_41[0][0]                     \n",
      "                                                                 add_42[0][0]                     \n",
      "                                                                 add_43[0][0]                     \n",
      "                                                                 add_44[0][0]                     \n",
      "                                                                 add_45[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 35,827\n",
      "Trainable params: 35,827\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "c_out = []\n",
    "zero_in = keras.layers.Input(shape=(feature_size,), name='zeros')\n",
    "last_out = dense_in(zero_in)\n",
    "for l_in, l_emb in embeddings:\n",
    "    last_out = keras.layers.add([dense_in(l_emb), dense_res(last_out)])\n",
    "    c_out.append(dense_out(last_out))\n",
    "\n",
    "model = keras.Model([zero_in,] + list(c_in), c_out)\n",
    "model.compile(optimizer='Adam', loss=keras.losses.sparse_categorical_crossentropy)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75111, 42), (8, 75111), (8, 75111))"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_pad = np.tile(np.zeros(feature_size), (len(x[0]), 1))\n",
    "zero_pad.shape, np.array(x).shape, np.array(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "75111/75111 [==============================] - 18s 242us/step - loss: 17.7442 - dense_3_loss_1: 2.4914 - dense_3_loss_2: 2.3287 - dense_3_loss_3: 2.2089 - dense_3_loss_4: 2.1670 - dense_3_loss_5: 2.1419 - dense_3_loss_6: 2.1370 - dense_3_loss_7: 2.1474 - dense_3_loss_8: 2.1220\n",
      "Epoch 2/6\n",
      "75111/75111 [==============================] - 18s 242us/step - loss: 17.6919 - dense_3_loss_1: 2.4893 - dense_3_loss_2: 2.3259 - dense_3_loss_3: 2.2031 - dense_3_loss_4: 2.1604 - dense_3_loss_5: 2.1340 - dense_3_loss_6: 2.1278 - dense_3_loss_7: 2.1376 - dense_3_loss_8: 2.1138\n",
      "Epoch 3/6\n",
      "75111/75111 [==============================] - 18s 241us/step - loss: 17.6499 - dense_3_loss_1: 2.4880 - dense_3_loss_2: 2.3242 - dense_3_loss_3: 2.1992 - dense_3_loss_4: 2.1533 - dense_3_loss_5: 2.1273 - dense_3_loss_6: 2.1217 - dense_3_loss_7: 2.1293 - dense_3_loss_8: 2.1069\n",
      "Epoch 4/6\n",
      "75111/75111 [==============================] - 18s 236us/step - loss: 17.6106 - dense_3_loss_1: 2.4871 - dense_3_loss_2: 2.3229 - dense_3_loss_3: 2.1943 - dense_3_loss_4: 2.1467 - dense_3_loss_5: 2.1206 - dense_3_loss_6: 2.1155 - dense_3_loss_7: 2.1233 - dense_3_loss_8: 2.1002\n",
      "Epoch 5/6\n",
      "75111/75111 [==============================] - 18s 235us/step - loss: 17.5795 - dense_3_loss_1: 2.4863 - dense_3_loss_2: 2.3221 - dense_3_loss_3: 2.1919 - dense_3_loss_4: 2.1422 - dense_3_loss_5: 2.1149 - dense_3_loss_6: 2.1105 - dense_3_loss_7: 2.1174 - dense_3_loss_8: 2.0943\n",
      "Epoch 6/6\n",
      "75111/75111 [==============================] - 18s 237us/step - loss: 17.5548 - dense_3_loss_1: 2.4863 - dense_3_loss_2: 2.3199 - dense_3_loss_3: 2.1892 - dense_3_loss_4: 2.1381 - dense_3_loss_5: 2.1113 - dense_3_loss_6: 2.1068 - dense_3_loss_7: 2.1124 - dense_3_loss_8: 2.0908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b30141ebe0>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([zero_pad] + x, y, batch_size=64, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(seqs):\n",
    "    seq_idx = [char2idx[c] for c in seqs[-seq_len:]]\n",
    "    props = model.predict([np.zeros(feature_size)[np.newaxis, :]] + [np.array(i)[np.newaxis] for i in seq_idx])\n",
    "    return ''.join([chars[np.argmax(p)] for p in props])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thet tn '"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(\" this is\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use same embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 75111), (8, 75111))"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data\n",
    "seq_len = 8\n",
    "x = [np.array([idx[i + offset] for i in range(0, len(idx)-1-seq_len, seq_len)]) for offset in range(seq_len)]\n",
    "y = [np.array([idx[i + offset] for i in range(1, len(idx)-1-seq_len, seq_len)]) for offset in range(seq_len)]\n",
    "\n",
    "np.array(x).shape, np.array(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([40,  1, 33,  2, 72, 67, 73,  2, 68, 57]),\n",
       " array([42,  1, 38, 44,  2,  9, 61, 73, 73,  1]),\n",
       " array([29, 43, 31, 71, 54,  9, 58, 61,  2, 59]),\n",
       " array([30, 45,  2, 74,  2, 76, 67, 58, 60, 68]),\n",
       " array([25, 40, 73, 73, 76, 61, 24, 71, 71, 71]),\n",
       " array([27, 40, 61, 61, 68, 54,  2, 58, 68,  2]),\n",
       " array([29, 39, 54,  2, 66, 73, 33,  2, 74, 72]),\n",
       " array([ 1, 43, 73, 62, 54,  2, 72, 67, 67, 74])]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[i][:10] for i in range(seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([42,  1, 38, 44,  2,  9, 61, 73, 73,  1]),\n",
       " array([29, 43, 31, 71, 54,  9, 58, 61,  2, 59]),\n",
       " array([30, 45,  2, 74,  2, 76, 67, 58, 60, 68]),\n",
       " array([25, 40, 73, 73, 76, 61, 24, 71, 71, 71]),\n",
       " array([27, 40, 61, 61, 68, 54,  2, 58, 68,  2]),\n",
       " array([29, 39, 54,  2, 66, 73, 33,  2, 74, 72]),\n",
       " array([ 1, 43, 73, 62, 54,  2, 72, 67, 67, 74])]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y[i][:10] for i in range(seq_len-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_emb = keras.layers.Embedding(input_dim=vocab_size, output_dim=feature_size, input_length=1)\n",
    "def create_input(name):\n",
    "    inp = keras.layers.Input(shape=(1,), dtype=np.int32, name=name)\n",
    "    return inp, keras.layers.Flatten()(seq_emb(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "c1 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 1, 42)        3570        c0[0][0]                         \n",
      "                                                                 c1[0][0]                         \n",
      "                                                                 c2[0][0]                         \n",
      "                                                                 c3[0][0]                         \n",
      "                                                                 c4[0][0]                         \n",
      "                                                                 c5[0][0]                         \n",
      "                                                                 c6[0][0]                         \n",
      "                                                                 c7[0][0]                         \n",
      "                                                                 c8[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 42)           0           embedding_27[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 42)           0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "seq_dense_in (Dense)            (None, 256)          11008       flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "                                                                 flatten_36[0][0]                 \n",
      "                                                                 flatten_37[0][0]                 \n",
      "                                                                 flatten_38[0][0]                 \n",
      "                                                                 flatten_39[0][0]                 \n",
      "                                                                 flatten_40[0][0]                 \n",
      "                                                                 flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "c2 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "seq_dense_res (Dense)           (None, 256)          65792       seq_dense_in[0][0]               \n",
      "                                                                 add_68[0][0]                     \n",
      "                                                                 add_69[0][0]                     \n",
      "                                                                 add_70[0][0]                     \n",
      "                                                                 add_71[0][0]                     \n",
      "                                                                 add_72[0][0]                     \n",
      "                                                                 add_73[0][0]                     \n",
      "                                                                 add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 256)          0           seq_dense_in[1][0]               \n",
      "                                                                 seq_dense_res[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 42)           0           embedding_27[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c3 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 256)          0           seq_dense_in[2][0]               \n",
      "                                                                 seq_dense_res[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 42)           0           embedding_27[3][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c4 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 256)          0           seq_dense_in[3][0]               \n",
      "                                                                 seq_dense_res[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 42)           0           embedding_27[4][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c5 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 256)          0           seq_dense_in[4][0]               \n",
      "                                                                 seq_dense_res[3][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 42)           0           embedding_27[5][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c6 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 256)          0           seq_dense_in[5][0]               \n",
      "                                                                 seq_dense_res[4][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 42)           0           embedding_27[6][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c7 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 256)          0           seq_dense_in[6][0]               \n",
      "                                                                 seq_dense_res[5][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 42)           0           embedding_27[7][0]               \n",
      "__________________________________________________________________________________________________\n",
      "c8 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, 256)          0           seq_dense_in[7][0]               \n",
      "                                                                 seq_dense_res[6][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)            (None, 42)           0           embedding_27[8][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 256)          0           seq_dense_in[8][0]               \n",
      "                                                                 seq_dense_res[7][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 85)           21845       add_68[0][0]                     \n",
      "                                                                 add_69[0][0]                     \n",
      "                                                                 add_70[0][0]                     \n",
      "                                                                 add_71[0][0]                     \n",
      "                                                                 add_72[0][0]                     \n",
      "                                                                 add_73[0][0]                     \n",
      "                                                                 add_74[0][0]                     \n",
      "                                                                 add_75[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 102,215\n",
      "Trainable params: 102,215\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embeddings = [create_input('c{0}'.format(i)) for i in range(seq_len + 1)]\n",
    "c_in, c_emb = list(zip(*embeddings))\n",
    "\n",
    "# dense layers\n",
    "dense_in = keras.layers.Dense(dense_size,activation='relu', name='seq_dense_in')\n",
    "dense_res = keras.layers.Dense(dense_size, activation='relu', name='seq_dense_res', kernel_initializer='identity')\n",
    "dense_out = keras.layers.Dense(vocab_size, activation='softmax')\n",
    "\n",
    "# Model\n",
    "c_out = []\n",
    "last_out = dense_in(c_emb[0])\n",
    "for l_in, l_emb in embeddings[1:]:\n",
    "    last_out = keras.layers.add([dense_in(l_emb), dense_res(last_out)])\n",
    "    c_out.append(dense_out(last_out))\n",
    "\n",
    "model = keras.Model(c_in, c_out)\n",
    "model.compile(optimizer='Adam', loss=keras.losses.sparse_categorical_crossentropy)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "75111/75111 [==============================] - 18s 245us/step - loss: 19.6434 - dense_22_loss_1: 2.6487 - dense_22_loss_2: 2.5083 - dense_22_loss_3: 2.4423 - dense_22_loss_4: 2.4167 - dense_22_loss_5: 2.4014 - dense_22_loss_6: 2.4054 - dense_22_loss_7: 2.4145 - dense_22_loss_8: 2.4060\n",
      "Epoch 2/4\n",
      "75111/75111 [==============================] - 17s 224us/step - loss: 17.6584 - dense_22_loss_1: 2.5209 - dense_22_loss_2: 2.3466 - dense_22_loss_3: 2.2024 - dense_22_loss_4: 2.1416 - dense_22_loss_5: 2.1134 - dense_22_loss_6: 2.1113 - dense_22_loss_7: 2.1209 - dense_22_loss_8: 2.1012\n",
      "Epoch 3/4\n",
      "75111/75111 [==============================] - 17s 223us/step - loss: 17.1729 - dense_22_loss_1: 2.5123 - dense_22_loss_2: 2.3352 - dense_22_loss_3: 2.1565 - dense_22_loss_4: 2.0715 - dense_22_loss_5: 2.0313 - dense_22_loss_6: 2.0243 - dense_22_loss_7: 2.0321 - dense_22_loss_8: 2.0097\n",
      "Epoch 4/4\n",
      "75111/75111 [==============================] - 17s 223us/step - loss: 16.8622 - dense_22_loss_1: 2.5097 - dense_22_loss_2: 2.3296 - dense_22_loss_3: 2.1327 - dense_22_loss_4: 2.0284 - dense_22_loss_5: 1.9784 - dense_22_loss_6: 1.9654 - dense_22_loss_7: 1.9711 - dense_22_loss_8: 1.9470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b30b40afd0>"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([np.zeros(len(x[0]))] + list(x), y, batch_size=64, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(seqs):\n",
    "    seq_idx = [char2idx[c] for c in seqs[-seq_len:]]\n",
    "    props = model.predict([np.zeros(1),] + [np.array(i)[np.newaxis] for i in seq_idx])\n",
    "    print(seqs[-seq_len+1:] + '\\n' + ''.join([chars[np.argmax(p)] for p in props]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part of\n",
      "torn of \n"
     ]
    }
   ],
   "source": [
    "test_model(\" this is part of\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras RNN Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75111, 8), (75111, 8))"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data\n",
    "seq_len = 8\n",
    "x = [np.array([idx[i + offset] for i in range(0, len(idx)-1-seq_len, seq_len)]) for offset in range(seq_len)]\n",
    "y = [np.array([idx[i + offset] for i in range(1, len(idx)-1-seq_len, seq_len)]) for offset in range(seq_len)]\n",
    "x = np.stack(x, axis=1)\n",
    "y = np.stack(y, axis=1)\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_35 (Embedding)     (None, 8, 42)             3570      \n",
      "_________________________________________________________________\n",
      "simple_rnn_9 (SimpleRNN)     (None, 8, 256)            76544     \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 8, 256)            65792     \n",
      "=================================================================\n",
      "Total params: 145,906\n",
      "Trainable params: 145,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=vocab_size, output_dim=feature_size, input_length=seq_len),\n",
    "    keras.layers.SimpleRNN(dense_size,activation='relu', return_sequences=True, recurrent_initializer='identity'),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(dense_size, activation='softmax')),\n",
    "    #keras.layers.Dense(dense_size, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam', loss=keras.losses.sparse_categorical_crossentropy)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75111/75111 [==============================] - 7s 99us/step - loss: 2.8037\n",
      "Epoch 2/8\n",
      "75111/75111 [==============================] - ETA: 0s - loss: 2.190 - 6s 82us/step - loss: 2.1893\n",
      "Epoch 3/8\n",
      "75111/75111 [==============================] - 6s 81us/step - loss: 2.0219\n",
      "Epoch 4/8\n",
      "75111/75111 [==============================] - 6s 80us/step - loss: 1.9309\n",
      "Epoch 5/8\n",
      "75111/75111 [==============================] - 6s 80us/step - loss: 1.8729\n",
      "Epoch 6/8\n",
      "75111/75111 [==============================] - 6s 80us/step - loss: 1.8319\n",
      "Epoch 7/8\n",
      "75111/75111 [==============================] - 6s 83us/step - loss: 1.8010\n",
      "Epoch 8/8\n",
      "75111/75111 [==============================] - 6s 83us/step - loss: 1.7773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b311a157f0>"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, np.atleast_3d(y), batch_size=128, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(seq):\n",
    "    seq_idx = [char2idx[c] for c in seq[-seq_len:]]\n",
    "    prop = model.predict(np.array([seq_idx])).squeeze()\n",
    "    return ''.join([chars[np.argmax(p)] for p in prop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' tn t  a'"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' this is an ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_39 (Embedding)     (64, 8, 42)               3570      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (64, 8, 42)               168       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (64, 8, 256)              306176    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (64, 8, 85)               21845     \n",
      "=================================================================\n",
      "Total params: 331,759\n",
      "Trainable params: 331,675\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=vocab_size, output_dim=feature_size, input_length=seq_len,\n",
    "                           batch_input_shape=(batch_size, seq_len)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LSTM(dense_size, return_sequences=True, stateful=True),\n",
    "    keras.layers.Dense(vocab_size, activation='softmax'),\n",
    "])\n",
    "model.compile(optimizer='Adam', loss=keras.losses.sparse_categorical_crossentropy)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "75072/75072 [==============================] - 16s 218us/step - loss: 2.2772\n",
      "Epoch 2/4\n",
      "75072/75072 [==============================] - 14s 193us/step - loss: 2.0184\n",
      "Epoch 3/4\n",
      "75072/75072 [==============================] - 15s 193us/step - loss: 1.9449\n",
      "Epoch 4/4\n",
      "75072/75072 [==============================] - 14s 189us/step - loss: 1.9035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b31daa65c0>"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_size = (len(x) // batch_size) * batch_size\n",
    "model.fit(x[:fixed_size], np.atleast_3d(y[:fixed_size]), epochs=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
