{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run env_setup.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from lessdeep.datasets.grouplens import movielens, movielens_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = movielens.download_data()\n",
    "sample_path = movielens_small.download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = sample_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_csv(os.path.join(path, 'ratings.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for display purpose read movie names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_names = pd.read_csv(os.path.join(path, 'movies.csv')).set_index('movieId')['title'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = rating['userId'].unique()\n",
    "movies = rating['movieId'].unique()\n",
    "userid2index = {o : i for i, o in enumerate(users)}\n",
    "movieid2index = {o : i for i, o in enumerate(movies)}\n",
    "\n",
    "rating.movieId = rating.movieId.apply(lambda x: movieid2index[x])\n",
    "rating.userId = rating.userId.apply(lambda x: userid2index[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671, 9066)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = rating.userId.nunique()\n",
    "n_movies = rating.movieId.nunique()\n",
    "n_users, n_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79831, 20173)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "train_select = np.random.rand(len(rating)) < 0.8\n",
    "train_set = rating[train_select]\n",
    "val_set = rating[~train_select]\n",
    "(len(train_set), len(val_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_in = keras.layers.Input(shape=(1,), dtype=rating.userId.dtype, name='user_in')\n",
    "user_embedding = keras.layers.Embedding(input_dim=n_users, output_dim=n_factors,\n",
    "                                        embeddings_regularizer=keras.regularizers.l2(1e-4))(user_in)\n",
    "movie_in = keras.layers.Input(shape=(1,), dtype=rating.movieId.dtype, name='movie_in')\n",
    "movie_embedding = keras.layers.Embedding(input_dim=n_movies, output_dim=n_factors,\n",
    "                                         embeddings_regularizer=keras.regularizers.l2(1e-4))(movie_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_in (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_in (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        33550       user_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 50)        453300      movie_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 1)         0           embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1)            0           dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 486,850\n",
      "Trainable params: 486,850\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#x = keras.layers.merge([user_embedding, movie_embedding], mode='dot')\n",
    "x = keras.layers.dot([user_embedding, movie_embedding], axes=(2, 2))\n",
    "x = keras.layers.Flatten()(x)\n",
    "model = keras.Model([user_in, movie_in], outputs=x)\n",
    "\n",
    "#import tensorflow as tf\n",
    "#run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "#run_metadata = tf.RunMetadata()\n",
    "model.compile(keras.optimizers.Adam(0.001), loss='mse') #, options=run_options, run_metadata=run_metadata)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoches, batch_size=512):\n",
    "    model.fit([train_set.userId, train_set.movieId], train_set.rating, batch_size=batch_size, epochs=epoches,\n",
    "              validation_data=([val_set.userId, val_set.movieId], val_set.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79831 samples, validate on 20173 samples\n",
      "Epoch 1/1\n",
      "79831/79831 [==============================] - 1s 17us/step - loss: 13.6755 - val_loss: 13.7333\n"
     ]
    }
   ],
   "source": [
    "train(1, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79831 samples, validate on 20173 samples\n",
      "Epoch 1/5\n",
      "79831/79831 [==============================] - 1s 9us/step - loss: 12.7807 - val_loss: 10.7542\n",
      "Epoch 2/5\n",
      "79831/79831 [==============================] - 1s 9us/step - loss: 7.2370 - val_loss: 4.7698\n",
      "Epoch 3/5\n",
      "79831/79831 [==============================] - 1s 9us/step - loss: 3.6316 - val_loss: 3.3362\n",
      "Epoch 4/5\n",
      "79831/79831 [==============================] - 1s 9us/step - loss: 2.7649 - val_loss: 2.9192\n",
      "Epoch 5/5\n",
      "79831/79831 [==============================] - 1s 9us/step - loss: 2.4414 - val_loss: 2.7480\n"
     ]
    }
   ],
   "source": [
    "train(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_in_1 (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_in_1 (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 50)        33550       user_in_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 50)        453300      movie_in_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1, 1)         0           embedding_3[0][0]                \n",
      "                                                                 embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 1)         671         user_in_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 1)         9066        movie_in_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1)            0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1)            0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1)            0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 496,587\n",
      "Trainable params: 496,587\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def embedding(input_dim, output_dim, dtype, name, regular=1e-4):\n",
    "    input_layer = keras.layers.Input(shape=(1,), dtype=rating.userId.dtype, name=name)\n",
    "    return input_layer, keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim,\n",
    "                                               embeddings_regularizer=keras.regularizers.l2(regular))(input_layer)\n",
    "user_in, user_emb = embedding(n_users, output_dim=n_factors, dtype=rating.userId.dtype, name=\"user_in_1\")\n",
    "movie_in, movie_emb = embedding(n_movies, output_dim=n_factors, dtype=rating.movieId.dtype, name=\"movie_in_1\")\n",
    "\n",
    "def create_bias(num):\n",
    "    return lambda input_l: keras.layers.Flatten()(keras.layers.Embedding(input_dim=num, output_dim=1)(input_l))\n",
    "\n",
    "x = keras.layers.dot([user_emb, movie_emb], axes=(2, 2))\n",
    "x = keras.layers.Flatten()(x)\n",
    "users_bias = create_bias(n_users)(user_in)\n",
    "movies_bias = create_bias(n_movies)(movie_in)\n",
    "x = keras.layers.add([x, users_bias, movies_bias])\n",
    "model_1 = keras.Model([user_in, movie_in], outputs=x)\n",
    "model_1.compile(keras.optimizers.Adam(0.001), loss='mse')\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoches, batch_size=512):\n",
    "    model.fit([train_set.userId, train_set.movieId], train_set.rating, batch_size=batch_size, epochs=epoches,\n",
    "              validation_data=([val_set.userId, val_set.movieId], val_set.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79831 samples, validate on 20173 samples\n",
      "Epoch 1/3\n",
      "79831/79831 [==============================] - 1s 15us/step - loss: 5.9072 - val_loss: 2.3067\n",
      "Epoch 2/3\n",
      "79831/79831 [==============================] - 1s 11us/step - loss: 2.0156 - val_loss: 2.1174\n",
      "Epoch 3/3\n",
      "79831/79831 [==============================] - 1s 10us/step - loss: 1.7788 - val_loss: 1.9977\n"
     ]
    }
   ],
   "source": [
    "model_1.optimizer.lr = 0.01\n",
    "train(model_1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79831 samples, validate on 20173 samples\n",
      "Epoch 1/6\n",
      "79831/79831 [==============================] - 1s 10us/step - loss: 1.5976 - val_loss: 1.8630\n",
      "Epoch 2/6\n",
      "79831/79831 [==============================] - 1s 10us/step - loss: 1.4259 - val_loss: 1.7443\n",
      "Epoch 3/6\n",
      "79831/79831 [==============================] - 1s 10us/step - loss: 1.2739 - val_loss: 1.6139\n",
      "Epoch 4/6\n",
      "79831/79831 [==============================] - 1s 10us/step - loss: 1.1327 - val_loss: 1.4983\n",
      "Epoch 5/6\n",
      "79831/79831 [==============================] - 1s 10us/step - loss: 1.0114 - val_loss: 1.3843\n",
      "Epoch 6/6\n",
      "79831/79831 [==============================] - 1s 11us/step - loss: 0.9044 - val_loss: 1.2912\n"
     ]
    }
   ],
   "source": [
    "model_1.optimizer.lr = 0.001\n",
    "train(model_1, 6, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby group rows with same key, here group users to each movie\n",
    "# then count users for each movie\n",
    "g = rating.groupby('movieId')['rating'].count()\n",
    "\n",
    "# take top 2000 most polular movies\n",
    "# the more user rating, the more popular the movie is. No matter rating is high or low\n",
    "g_top = g.sort_values(ascending=False)[:200]\n",
    "top_movie = np.array(g_top.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie bias\n",
    "movie bias means general property of the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbias_model = keras.Model(movie_in, movies_bias)\n",
    "top_mbiase = mbias_model.predict(top_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rating = [(b[0], movie_names[movies[i]]) for i, b in zip(top_movie, top_mbiase)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.26705092, 'Blair Witch Project, The (1999)'),\n",
       " (0.42768431, 'Dumb & Dumber (Dumb and Dumber) (1994)'),\n",
       " (0.49323946, 'Ace Ventura: When Nature Calls (1995)'),\n",
       " (0.55017078, 'Austin Powers: The Spy Who Shagged Me (1999)'),\n",
       " (0.57084793, 'Chicken Run (2000)'),\n",
       " (0.57818061, 'Ace Ventura: Pet Detective (1994)'),\n",
       " (0.60657442, 'Beetlejuice (1988)'),\n",
       " (0.62372738, 'Kill Bill: Vol. 1 (2003)'),\n",
       " (0.65086234, 'Meet the Parents (2000)'),\n",
       " (0.66375995, 'Kill Bill: Vol. 2 (2004)'),\n",
       " (0.67179209, 'Waterworld (1995)'),\n",
       " (0.68217385, 'Spider-Man (2002)'),\n",
       " (0.68540901, 'American Pie (1999)'),\n",
       " (0.68938136, 'Lethal Weapon (1987)'),\n",
       " (0.69118989, 'Clueless (1995)')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "sorted(pred_rating, key=itemgetter(0))[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.3445534, 'Shawshank Redemption, The (1994)'),\n",
       " (1.2478828, 'Heat (1995)'),\n",
       " (1.1993316, 'Rear Window (1954)'),\n",
       " (1.1493307, 'Fugitive, The (1993)'),\n",
       " (1.1267735, 'Silence of the Lambs, The (1991)'),\n",
       " (1.1224185, 'Fargo (1996)'),\n",
       " (1.1082902, 'Usual Suspects, The (1995)'),\n",
       " (1.1054639, \"Schindler's List (1993)\"),\n",
       " (1.1014304, 'Pulp Fiction (1994)'),\n",
       " (1.096014, 'Godfather, The (1972)'),\n",
       " (1.0873785, 'Léon: The Professional (a.k.a. The Professional) (Léon) (1994)'),\n",
       " (1.0763277, 'Clear and Present Danger (1994)'),\n",
       " (1.0734397, 'Dark Knight, The (2008)'),\n",
       " (1.0728868, 'Forrest Gump (1994)'),\n",
       " (1.0684099, 'Sense and Sensibility (1995)')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pred_rating, key=itemgetter(0), reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Embedding\n",
    "embedding is too large to analyze. We can use [PCA(Principal Component Analysis)](https://en.wikipedia.org/wiki/Principal_component_analysis) to find the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 50)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memb_model = keras.Model(movie_in, movie_emb)\n",
    "top_emb = np.squeeze(memb_model.predict(top_movie))\n",
    "top_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 200)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "movie_pca = PCA(n_components=3).fit(top_emb.T).components_\n",
    "movie_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_comp_0 = [(np.squeeze(em), movie_names[movies[i]]) for i, em in zip(top_movie, movie_pca[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.12532365, 'Lord of the Rings: The Fellowship of the Ring, The (2001)'),\n",
       " (-0.11365488, 'Pulp Fiction (1994)'),\n",
       " (-0.11153743, \"Schindler's List (1993)\"),\n",
       " (-0.11016429, 'Star Wars: Episode VI - Return of the Jedi (1983)'),\n",
       " (-0.11009175,\n",
       "  'Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)'),\n",
       " (-0.1077768, 'Lord of the Rings: The Return of the King, The (2003)'),\n",
       " (-0.10640314, 'Silence of the Lambs, The (1991)'),\n",
       " (-0.10548574, 'Star Wars: Episode IV - A New Hope (1977)'),\n",
       " (-0.10178412, 'Godfather: Part II, The (1974)'),\n",
       " (-0.1013743, 'Godfather, The (1972)'),\n",
       " (-0.10077167, 'Usual Suspects, The (1995)'),\n",
       " (-0.099855773, 'Seven (a.k.a. Se7en) (1995)'),\n",
       " (-0.096807972, 'Dark Knight, The (2008)'),\n",
       " (-0.09612079, 'Lord of the Rings: The Two Towers, The (2002)'),\n",
       " (-0.095977843, 'Terminator 2: Judgment Day (1991)')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(movie_comp_0, key=itemgetter(0))[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.017855579, 'Ace Ventura: When Nature Calls (1995)'),\n",
       " (-0.021866273, 'Batman Forever (1995)'),\n",
       " (-0.022151144, 'Twister (1996)'),\n",
       " (-0.029382469, 'Firm, The (1993)'),\n",
       " (-0.031611625, 'Broken Arrow (1996)'),\n",
       " (-0.031981662, 'Star Wars: Episode I - The Phantom Menace (1999)'),\n",
       " (-0.033278599, 'Pretty Woman (1990)'),\n",
       " (-0.034962945, 'Chicken Run (2000)'),\n",
       " (-0.03496344, 'Back to the Future Part II (1989)'),\n",
       " (-0.035524014, 'Net, The (1995)'),\n",
       " (-0.035920169, 'Blair Witch Project, The (1999)'),\n",
       " (-0.036154501, 'Demolition Man (1993)'),\n",
       " (-0.037076697, 'Happy Gilmore (1996)'),\n",
       " (-0.03742753, 'Waterworld (1995)'),\n",
       " (-0.038521368, 'Cliffhanger (1993)')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(movie_comp_0, key=itemgetter(0), reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_in_2 (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_in_2 (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_67 (Embedding)        (None, 1, 50)        33550       user_in_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_68 (Embedding)        (None, 1, 50)        453300      movie_in_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 1, 100)       0           embedding_67[0][0]               \n",
      "                                                                 embedding_68[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 100)          0           concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 100)          400         flatten_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 100)          0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 100)          10100       dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 100)          400         dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 100)          0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 1)            101         dropout_55[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 497,851\n",
      "Trainable params: 497,451\n",
      "Non-trainable params: 400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "user_in, user_emb = embedding(n_users, output_dim=n_factors, dtype=rating.userId.dtype, name=\"user_in_2\")\n",
    "movie_in, movie_emb = embedding(n_movies, output_dim=n_factors, dtype=rating.movieId.dtype, name=\"movie_in_2\")\n",
    "x = keras.layers.concatenate([user_emb, movie_emb])\n",
    "x = keras.layers.Flatten()(x)\n",
    "#x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.7)(x)\n",
    "x = keras.layers.Dense(100, activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(1)(x)\n",
    "nn = keras.Model([user_in, movie_in], x)\n",
    "nn.compile(keras.optimizers.Adam(), loss='mse')\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79831 samples, validate on 20173 samples\n",
      "Epoch 1/15\n",
      "79831/79831 [==============================] - 2s 30us/step - loss: 0.8309 - val_loss: 0.8320\n",
      "Epoch 2/15\n",
      "79831/79831 [==============================] - 2s 30us/step - loss: 0.8333 - val_loss: 0.8302\n",
      "Epoch 3/15\n",
      "79831/79831 [==============================] - 2s 30us/step - loss: 0.8269 - val_loss: 0.8310\n",
      "Epoch 4/15\n",
      "79831/79831 [==============================] - 2s 30us/step - loss: 0.8276 - val_loss: 0.8325\n",
      "Epoch 5/15\n",
      "79831/79831 [==============================] - 2s 30us/step - loss: 0.8280 - val_loss: 0.8326\n",
      "Epoch 6/15\n",
      "79831/79831 [==============================] - 2s 31us/step - loss: 0.8242 - val_loss: 0.8297\n",
      "Epoch 7/15\n",
      "79831/79831 [==============================] - 2s 31us/step - loss: 0.8221 - val_loss: 0.8335\n",
      "Epoch 8/15\n",
      "79831/79831 [==============================] - 2s 30us/step - loss: 0.8204 - val_loss: 0.8303\n",
      "Epoch 9/15\n",
      "79831/79831 [==============================] - 2s 30us/step - loss: 0.8169 - val_loss: 0.8304\n",
      "Epoch 10/15\n",
      "79831/79831 [==============================] - 2s 30us/step - loss: 0.8152 - val_loss: 0.8307\n",
      "Epoch 11/15\n",
      "79831/79831 [==============================] - 2s 30us/step - loss: 0.8114 - val_loss: 0.8269\n",
      "Epoch 12/15\n",
      "79831/79831 [==============================] - 2s 30us/step - loss: 0.8088 - val_loss: 0.8266\n",
      "Epoch 13/15\n",
      "79831/79831 [==============================] - 2s 30us/step - loss: 0.8131 - val_loss: 0.8254\n",
      "Epoch 14/15\n",
      "79831/79831 [==============================] - 2s 30us/step - loss: 0.8062 - val_loss: 0.8285\n",
      "Epoch 15/15\n",
      "79831/79831 [==============================] - 2s 30us/step - loss: 0.8036 - val_loss: 0.8299\n"
     ]
    }
   ],
   "source": [
    "nn.optimizer.lr = 0.0001\n",
    "train(nn, epoches=15, batch_size=2048)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
