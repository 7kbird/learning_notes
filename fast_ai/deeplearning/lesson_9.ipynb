{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run env_setup.py\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\dev\\libs\\Anaconda3\\envs\\tf140p35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#from tensorflow.contrib import keras\n",
    "import keras\n",
    "import bcolz\n",
    "from lessdeep.utils import download_file, extract_file\n",
    "from lessdeep.model.vgg16n import Vgg16N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_72_path = extract_file(download_file('http://files.fast.ai/data/trn_resized_72.tar.gz'))\n",
    "resized_288_path = extract_file(download_file('http://files.fast.ai/data/trn_resized_288.tar.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_lr = bcolz.open(resized_72_path) # Low resolution\n",
    "arr_hr = bcolz.open(resized_288_path) # High resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters, size, strides=(2,2), padding='same', activation=keras.activations.relu):\n",
    "    x = keras.layers.Conv2D(filters, kernel_size=size, strides=strides, padding=padding)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    return activation(x) if activation else x\n",
    "\n",
    "def res_block(x, filters=64):\n",
    "    y = conv_block(x, filters, 3, strides=(1,1))\n",
    "    y = conv_block(y, filters, 3, strides=(1,1), activation=None)\n",
    "    return keras.backend.sum([y, x], axis=0)\n",
    "\n",
    "def up_block(x, filters, size):\n",
    "    x = keras.layers.UpSampling2D()(x)\n",
    "    x = keras.layers.Conv2D(filters, size, padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    return keras.activations.relu(x)\n",
    "\n",
    "def deconv_block(x, filters, size, strides=(2,2)):\n",
    "    x = keras.layers.Conv2DTranspose(filters, size, strides=strides, padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    return keras.activations.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = keras.layers.Input(arr_lr.shape[1:])\n",
    "x = conv_block(inp, 64, 9, strides=(1,1))\n",
    "for _ in range(4):\n",
    "    x = res_block(x)\n",
    "x = up_block(x, 64, 3)\n",
    "x = up_block(x, 64, 3)\n",
    "x = keras.layers.Conv2D(3, 9, activation='tanh', padding='same')(x)\n",
    "out = keras.layers.Lambda(lambda x: (x + 1)*127.5)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = Vgg16N(include_top=False, image_size=arr_hr.shape[1:3])\n",
    "vgg_inp = vgg.model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in vgg.model.layers: l.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_out(model, i):\n",
    "    return model.model.layers[i].output\n",
    "\n",
    "conv_layers = keras.models.Model(vgg_inp, [get_layer_out(vgg, i) for i in [1, 4, 7]])\n",
    "vgg1 = conv_layers(out)\n",
    "vgg2 = conv_layers(vgg_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_4:0' shape=(?, 288, 288, 3) dtype=float32>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\dev\\\\libs\\\\Anaconda3\\\\envs\\\\tf140p35\\\\lib\\\\site-packages\\\\tensorflow\\\\contrib\\\\keras\\\\__init__.py'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_compare(img):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    ax1.imshow(img)\n",
    "    ax2.imshow(img)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
